{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Először importáljunk a könyvtárakat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STKneFuLKwr9"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ezután importáljuk be az adathalmazunkat és osszuk fel a tanító- és teszthalmazokra. Az összes számítást a tanító halmazon fogjuk végezni."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZtjhe61K_su"
      },
      "outputs": [],
      "source": [
        "X,y = load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A load_diabetes egy beépített függvény a scikit-learn könyvtárban.\n",
        "\n",
        "test_size=0.33: Ez azt jelzi, hogy az adatok 33%-a a teszthalmazba kerül, míg a maradék 67% a tanítóhalmazba.\n",
        "\n",
        "random_state=42: Ezzel az inicializált generátorral az adatok véletlenszerűen kerülnek szétosztásra, de azonos kezdeti állapot mellett minden futtatáskor ugyanazt az elosztást kapjuk.\n",
        "\n",
        "A max_features azt határozza meg, hogy a véletlen erdő (Random Forest) modell melyik részhalmazát használja a bemeneti jellemzőkből az egyes döntési fák építésekor.\n",
        "\n",
        "Az n_estimators azt határozza meg, hogy hány döntési fát használjunk a véletlen erdő modellben."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Greedy algoritmus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "greedy_start_time = time.time()\n",
        "\n",
        "greedy_best_score = -float('inf')  # Kezdeti legjobb pontszám\n",
        "greedy_best_params = None  # Kezdeti legjobb paraméterek\n",
        "\n",
        "n_estimators_values = []\n",
        "max_features_values = []\n",
        "mean_test_scores = []\n",
        "\n",
        "for n_estimators in range(5, 100, 5):\n",
        "    for max_features in np.arange(0.1, 1.0, 0.05):\n",
        "        # Modell létrehozása az adott paraméterekkel\n",
        "        model = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features, random_state=0)\n",
        "        \n",
        "        # Keresztvalidáció és pontszám kiszámítása\n",
        "        scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"r2\", n_jobs=-1)\n",
        "        mean_score = np.mean(scores)\n",
        "        \n",
        "        # Save values for plotting\n",
        "        n_estimators_values.append(n_estimators)\n",
        "        max_features_values.append(max_features)\n",
        "        mean_test_scores.append(mean_score)\n",
        "\n",
        "        # Ellenőrzés, hogy a pontszám jobb-e a jelenleginél\n",
        "        if mean_score > greedy_best_score:\n",
        "            greedy_best_score = mean_score\n",
        "            greedy_best_params = {'n_estimators': n_estimators, 'max_features': max_features}\n",
        "\n",
        "greedy_elapsed_time = time.time() - greedy_start_time\n",
        "\n",
        "print(f\"Legjobb hiperparaméterek kombinációja: {greedy_best_params}\")\n",
        "print(f\"Legjobb pontszám: {greedy_best_score}\")\n",
        "print(f\"Idő: {greedy_elapsed_time} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(n_estimators_values, max_features_values, c=mean_test_scores, cmap='viridis', marker='o', s=100, alpha=0.5)\n",
        "plt.colorbar(label='Mean Test Score')\n",
        "plt.xlabel('n_estimators')\n",
        "plt.ylabel('max_features')\n",
        "plt.title('Mean Test Score vs. n_estimators')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(n_estimators_values, mean_test_scores, c=mean_test_scores, cmap='viridis', marker='o', s=100, alpha=0.5)\n",
        "plt.xlabel('n_estimators')\n",
        "plt.ylabel('Mean Test Score')\n",
        "plt.title('Mean Test Score vs. n_estimators')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Most kezdjük el a rácskeresést. \n",
        "Bemenetként megadjuk a regresszorunkat, amit optimalizálni szeretnénk, a keresztező validációk számát, valamint a legjobb hiperparaméterértékek kiválasztásakor figyelembe venni kívánt pontozási metrikust. \n",
        "Az utolsó argumentum egy lista az egyes hiperparaméterek értékeinek felderítésére. A GridSearchCV létrehozza az összes lehetséges kombinációt.\n",
        "\n",
        "Tegyük fel, hogy a n_estimators hiperparamétert 5-től 100-ig szeretnénk beállítani 5 lépésenként, és a max_features hiperparamétert 0.1-től 1.0-ig 0.05 lépésenként. \n",
        "Azon kombinációkat keresjük, amelyek a 5-körös keresztező validációban az R2 érték átlagát maximálisra növelik.\n",
        "\n",
        "Véletlenszerű erdei regresszor.\n",
        "\n",
        "A véletlenszerű erdő egy metabecslő, amely számos osztályozó döntési fát illeszt az adatkészlet különböző almintáira, és átlagolást használ a prediktív pontosság javítására és a túlillesztés szabályozására.\n",
        "\n",
        "Amint elindítjuk a rácskeresést, a Python minden lehetséges érték kombinációt kipróbál a megadott listákban, és kiválasztja a legmagasabb pontszámot kapó kombinációt.\n",
        "\n",
        "Ez a folyamat eltarthat egy ideig, mivel a rács nagy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Grid search algoritmus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQHJqViqLEn3",
        "outputId": "83e6de7c-84b1-4683-aafd-b8e49610c889"
      },
      "outputs": [],
      "source": [
        "grid_start_time = time.time()\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestRegressor(random_state=0),\n",
        "                           {\n",
        "                              'n_estimators': np.arange(5, 100, 5),\n",
        "                              'max_features': np.arange(0.1, 1.0, 0.05),\n",
        "                            },\n",
        "                            cv=5, scoring=\"r2\", verbose=1, n_jobs=-1\n",
        "                           )\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "grid_elapsed_time = time.time() - grid_start_time\n",
        "\n",
        "print(\"Legjobb hiperparaméterek kombinációja:\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"Legjobb pontszám:\")\n",
        "print(grid_search.best_score_)\n",
        "print(f\"Idő: {grid_elapsed_time} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = grid_search.cv_results_\n",
        "n_estimators = results['param_n_estimators']\n",
        "max_features = results['param_max_features']\n",
        "mean_test_score = results['mean_test_score']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(n_estimators, max_features, c=mean_test_score, cmap='viridis', marker='o', s=100, alpha=0.5)\n",
        "plt.colorbar(label='Mean Test Score')\n",
        "plt.xlabel('n_estimators')\n",
        "plt.ylabel('max_features')\n",
        "plt.title('Mean Test Score vs. n_estimators')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(n_estimators, mean_test_score, c=mean_test_score, cmap='viridis', marker='o', s=100, alpha=0.5)\n",
        "plt.xlabel('n_estimators')\n",
        "plt.ylabel('Mean Test Score')\n",
        "plt.title('Mean Test Score vs. n_estimators')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Most csak 250 illesztést (5 illesztés 50 iterációval) dolgozunk, és a folyamat csak pár másodpercet vesz igénybe az eredmény eléréséhez."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random search algoritmus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hegQ2NlZLlp8",
        "outputId": "b60f0b43-8440-46f1-d0c7-0216105b9566"
      },
      "outputs": [],
      "source": [
        "random_start_time = time.time()\n",
        "\n",
        "random_search = RandomizedSearchCV(RandomForestRegressor(random_state=0),\n",
        "                           {\n",
        "                              'n_estimators': np.arange(5, 100, 5),\n",
        "                              'max_features': np.arange(0.1, 1.0, 0.05),\n",
        "                            },\n",
        "                            cv=5, scoring=\"r2\", verbose=1, n_jobs=-1,\n",
        "                            n_iter=50, random_state=0\n",
        "                           )\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "random_elapsed_time = time.time() - random_start_time\n",
        "\n",
        "print(\"Legjobb hiperparaméterek kombinációja:\")\n",
        "print(random_search.best_params_)\n",
        "print(\"Legjobb pontszám:\")\n",
        "print(random_search.best_score_)\n",
        "print(f\"Idő: {random_elapsed_time} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = random_search.cv_results_\n",
        "n_estimators = results['param_n_estimators']\n",
        "max_features = results['param_max_features']\n",
        "mean_test_score = results['mean_test_score']\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(n_estimators, max_features, c=mean_test_score, cmap='viridis', marker='o', s=100, alpha=0.5)\n",
        "plt.colorbar(label='Mean Test Score')\n",
        "plt.xlabel('n_estimators')\n",
        "plt.ylabel('max_features')\n",
        "plt.title('Mean Test Score vs. n_estimators')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(n_estimators, mean_test_score, c=mean_test_score, cmap='viridis', marker='o', s=100, alpha=0.5)\n",
        "plt.xlabel('n_estimators')\n",
        "plt.ylabel('Mean Test Score')\n",
        "plt.title('Mean Test Score vs. n_estimators')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Láthatjuk, hogy az eredmény nagyon hasonló a rácskeresés által talált eredményhez, de a véletlen keresés sokkal csökkentette a számítási időt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Azt gondolom, hogy a három algoritmus közül a véletlen keresés nagyon hasznos, mert gyorsabb, és mivel nem éri el a rács legjobb pontját, elkerüli az overfittinget, és jobban képes általánosítani. \n",
        "\n",
        "Azonban kis rácsok esetén (azaz kevesebb, mint 200 pont) javaslom a rácskeresés használatát, ha a tanítási fázis nem túl lassú. \n",
        "\n",
        "Általános célú esetekben a véletlen keresés növelheti a tanítási sebességet és elérhet egy elfogadható jó megoldást a modelünkhöz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Az \"overfitting\" (túltanítás) egy olyan fogalom a gépi tanulásban, amely akkor jelentkezik, amikor egy modell túl jól alkalmazkodik a tanítóadathoz, és emiatt nem képes általánosítani a tanítóadaton kívüli adatokra.\n",
        "\n",
        "Az overfitting során a modell túlságosan bonyolultsá válik, és olyan zajt és véletlen változásokat is megtanul a tanítóadatban, amelyek nem relevánsak az általánosításhoz."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOQO6uVD2Sp+a9ND0Th2m6s",
      "include_colab_link": true,
      "name": "Grid search and random search.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
